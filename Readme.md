
# ğŸ™ï¸ AIagenti01 â€” Speech-to-Text â†’ LLM

Tento projekt je lokÃ¡lnÃ­ AI agent pro pÅ™epis audio souborÅ¯ pomocÃ­ Whisper a nÃ¡slednÃ© zpracovÃ¡nÃ­ vÃ½slednÃ©ho textu lokÃ¡lnÃ­m LLM (Ollama).

HlavnÃ­ zmÄ›ny v aktuÃ¡lnÃ­ verzi:
- Projekt pouÅ¾Ã­vÃ¡ Python 3.12.
- ProstÅ™edÃ­ se nastavuje pomocÃ­ dodanÃ½ch skriptÅ¯ `setup_env.ps1` / `setup_env.sh` (vyuÅ¾Ã­vajÃ­ `uv`).
- SpouÅ¡tÄ›cÃ­ nÃ¡stroj je `tools_ollama_whisper.py` (doporuÄeno spouÅ¡tÄ›t pÅ™es `uv run`).

---

## ğŸ§° Technologie

- Python 3.12
- uv (sprÃ¡vce prostÅ™edÃ­ a zÃ¡vislostÃ­)
- openai-whisper (Whisper wrapper)
- torch (PyTorch)
- ollama (lokÃ¡lnÃ­ LLM klient)

---

## ğŸ“ DÅ¯leÅ¾itÃ© soubory

```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ tools_ollama_whisper.py    # hlavnÃ­ nÃ¡stroj pro pÅ™epis a volÃ¡nÃ­ Ollama
â”œâ”€â”€ setup_env.ps1             # PowerShell helper pro Windows
â”œâ”€â”€ setup_env.sh              # shell helper pro Linux/macOS
â”œâ”€â”€ pyproject.toml            # metadata projektu
â”œâ”€â”€ uv.lock                   # generovanÃ½ lock file (uv)
â””â”€â”€ Readme.md
```

---

## âš™ï¸ RychlÃ© nastavenÃ­ (doporuÄeno)

Na Windows (PowerShell) spusÅ¥te (v koÅ™enovÃ©m adresÃ¡Å™i projektu):

```powershell
.\setup_env.ps1
```

Skript vytvoÅ™Ã­/aktualizuje virtuÃ¡lnÃ­ prostÅ™edÃ­ `aiagenti_venv_01`, aktivuje ho a nainstaluje zÃ¡vislosti.

AlternativnÄ› (ruÄnÄ›):

```powershell
python -m venv aiagenti_venv_01
.\aiagenti_venv_01\Scripts\Activate.ps1
pip install -r requirements.txt
```

Na Linux/macOS pouÅ¾ijte `setup_env.sh` nebo standardnÃ­ `python3 -m venv` a `source` aktivaci.

---

## â–¶ï¸ SpuÅ¡tÄ›nÃ­ nÃ¡stroje

NejjednoduÅ¡Å¡Ã­ (pokud pouÅ¾Ã­vÃ¡te `uv` a chcete spustit nÃ¡stroj v izolovanÃ©m prostÅ™edÃ­):

```powershell
uv run .\tools_ollama_whisper.py -- samples/ucebnice10.mp3
```

Nebo aktivujte venv a spusÅ¥te pÅ™Ã­mo Pythonem:

```powershell
.\aiagenti_venv_01\Scripts\Activate.ps1
python tools_ollama_whisper.py samples/ucebnice10.mp3
```

Parametry (pÅ™ehled):

- `--whisper-model` : tiny|base|small|medium|large (volitelnÃ©)
- `--language` : pokud chcete vynutit jazyk mÃ­sto automatickÃ© detekce

---

## ğŸ”§ Konfigurace Ollama

Nastavte promÄ›nnou prostÅ™edÃ­ na URL lokÃ¡lnÃ­ho Ollama API (vÃ½chozÃ­):

Windows PowerShell:

```powershell
$env:OLLAMA_API_URL = "http://localhost:3210"
```

Linux/macOS:

```bash
export OLLAMA_API_URL="http://localhost:3210"
```

StÃ¡hnÄ›te a spusÅ¥te model pÅ™es Ollama:

```bash
ollama pull llama3.1
ollama run llama3.1
```

---

## Tipy a Å™eÅ¡enÃ­ problÃ©mÅ¯

- Pokud `uv` vykazuje chybu ohlednÄ› `uv.lock`, smaÅ¾te `uv.lock` a pÅ™egenerujte jej pÅ™Ã­kazem `uv pip compile pyproject.toml -o uv.lock`.
- Pokud Windows zablokuje soubory pÅ™i odstraÅˆovÃ¡nÃ­ venv, ukonÄete bÄ›Å¾Ã­cÃ­ Python procesy nebo pouÅ¾ijte `rmdir /s /q` z cmd s oprÃ¡vnÄ›nÃ­m.

---

## Kontakt

Pokud chcete dalÅ¡Ã­ Ãºpravy (napÅ™. pÅ™idat dÃ¡vkovÃ© zpracovÃ¡nÃ­ nebo webovÃ© UI), napiÅ¡te a rÃ¡d pomohu.
